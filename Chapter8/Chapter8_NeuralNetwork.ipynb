{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462",
   "display_name": "Python 3.8.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 第8章: ニューラルネット\n",
    "\n",
    "[https://nlp100.github.io/ja/ch08.html](https://nlp100.github.io/ja/ch08.html)\n",
    "\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 70. 単語ベクトルの和による特徴量"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "# global\n",
    "dataset_types = ['train', 'valid', 'test']\n",
    "\n",
    "def makeDatasetFiles():\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Word2Vec\n",
    "    w2v = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        '../Chapter7/GoogleNews-vectors-negative300.bin', \n",
    "        binary=True)\n",
    "\n",
    "    # Load texts and make tensors\n",
    "    Xs, ys = {}, {}\n",
    "    dataset_types = ['train', 'valid', 'test']\n",
    "    label2int = {\n",
    "        \"b\": 0,\n",
    "        \"t\": 1,\n",
    "        \"e\": 2,\n",
    "        \"m\": 3\n",
    "    }\n",
    "\n",
    "    for dataset in dataset_types:\n",
    "        tmp_x, tmp_y = [], []\n",
    "        tmp_df = pd.read_table('../Chapter6/{:}.txt'.format(dataset))\n",
    "\n",
    "        for each in tmp_df.itertuples():\n",
    "\n",
    "            # make X\n",
    "            tokens = [token for token in nlp(each.TITLE)]\n",
    "            num_tokens = len(tokens)\n",
    "\n",
    "            x_i = np.zeros(300)\n",
    "            for token in tokens:\n",
    "                try:\n",
    "                    token_embedding = w2v[str(token)]\n",
    "                    x_i = np.add(x_i, token_embedding)\n",
    "\n",
    "                except KeyError:\n",
    "                    num_tokens -= 1\n",
    "                    continue\n",
    "\n",
    "            x_i = np.divide(x_i, num_tokens)\n",
    "            tmp_x.append(x_i)\n",
    "\n",
    "            # make y\n",
    "            tmp_y.append(label2int[each.CATEGORY])\n",
    "        \n",
    "        # convert to torch.Tensor\n",
    "        Xs[dataset] = torch.Tensor(tmp_x)\n",
    "        ys[dataset] = torch.Tensor(tmp_y)\n",
    "\n",
    "        # pickle\n",
    "        torch.save(Xs[dataset], 'X_{:}.pickle'.format(dataset))\n",
    "        torch.save(ys[dataset], 'y_{:}.pickle'.format(dataset))\n",
    "    \n",
    "    return Xs, ys"
   ]
  },
  {
   "source": [
    "## 71. 単層ニューラルネットワークによる予測"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for dataset in dataset_types:\n",
    "        Xs[dataset] = torch.load('X_{:}.pickle'.format(dataset))\n",
    "        ys[dataset] = torch.load('y_{:}.pickle'.format(dataset))\n",
    "except FileNotFoundError:\n",
    "    Xs, ys = makeDatasetFiles()\n",
    "    assert Xs != {} and ys != {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}