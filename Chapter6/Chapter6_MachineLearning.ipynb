{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章: 機械学習\n",
    "本章では，Fabio Gasparetti氏が公開しているNews Aggregator Data Setを用い，ニュース記事の見出しを「ビジネス」「科学技術」「エンターテイメント」「健康」のカテゴリに分類するタスク（カテゴリ分類）に取り組む．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. データの入手・整形\n",
    "\n",
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "1. ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
    "2. 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
    "3. 抽出された事例をランダムに並び替える．\n",
    "4. 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
    "\n",
    "学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "news_corpora = \"NewsAggregatorDataset/newsCorpora.csv\"\n",
    "columns = [\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"]\n",
    "\n",
    "df = pd.read_csv(news_corpora, delimiter=\"\\t\", header=None, index_col=0, names=columns)\n",
    "\n",
    "target_publisher = [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "df = df[df[\"PUBLISHER\"].isin(target_publisher)]\n",
    "\n",
    "# https://stackoverflow.com/questions/15772009/shuffling-permutating-a-dataframe-in-pandas\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "df_size = len(df)\n",
    "train_size, valid_test_size = int(df_size*0.8), int(df_size*0.1)\n",
    "assert df_size == train_size + valid_test_size * 2\n",
    "\n",
    "df_train = df.iloc[:train_size].reset_index(drop=True)\n",
    "df_valid = df.iloc[train_size:train_size+valid_test_size].reset_index(drop=True)\n",
    "df_test = df.iloc[train_size+valid_test_size:].reset_index(drop=True)\n",
    "\n",
    "df_train[[\"CATEGORY\", \"TITLE\"]].to_csv(\"train.txt\", index=False, sep=\"\\t\", encoding=\"utf-8\")\n",
    "df_valid[[\"CATEGORY\", \"TITLE\"]].to_csv(\"valid.txt\", index=False, sep=\"\\t\", encoding=\"utf-8\")\n",
    "df_test[[\"CATEGORY\", \"TITLE\"]].to_csv(\"test.txt\", index=False, sep=\"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10672, 7), (1334, 7), (1334, 7))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 51. 特徴量抽出\n",
    "\n",
    "学習データ，検証データ，評価データから特徴量を抽出し，それぞれtrain.feature.txt，valid.feature.txt，test.feature.txtというファイル名で保存せよ． なお，カテゴリ分類に有用そうな特徴量は各自で自由に設計せよ．記事の見出しを単語列に変換したものが最低限のベースラインとなるであろう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# https://universaldependencies.org/docs/u/pos/\n",
    "open_class_words = [\"ADJ\", \"ADV\", \"INTJ\", \"NOUN\", \"PROPN\", \"VERB\"]\n",
    "\n",
    "label2int = {\n",
    "    \"b\": 0,\n",
    "    \"t\": 1,\n",
    "    \"e\": 2,\n",
    "    \"m\": 3\n",
    "}\n",
    "int2label = {i:label for label, i in label2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力された Title の DataSeries から Vocabulary を作成\n",
    "def makeVocab(dataseries, threshold=10):\n",
    "    vocab2int, int2vocab = {}, {}\n",
    "    vocab_count = {}\n",
    "    \n",
    "    for token in [token for title in dataseries for token in nlp(title.lower())]:\n",
    "        if token.pos_ in open_class_words:\n",
    "            if token.lemma_ not in vocab_count.keys():\n",
    "                vocab_count[token.lemma_] = 1\n",
    "            else:\n",
    "                vocab_count[token.lemma_] += 1\n",
    "\n",
    "    index = 0    \n",
    "    for word, count in vocab_count.items():\n",
    "        if count > threshold:\n",
    "            vocab2int[word] = index\n",
    "            int2vocab[index] = word\n",
    "            index += 1\n",
    "\n",
    "    return vocab2int, int2vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words を作る\n",
    "def makeBOW(dataseries, vocab2int):\n",
    "    bow = []\n",
    "    \n",
    "    for title in dataseries:\n",
    "        current_bag = [0] * (len(vocab2int) + 1)\n",
    "\n",
    "        for token in nlp(title.lower()):\n",
    "            if token.pos_ in open_class_words:\n",
    "                if token.lemma_ in vocab2int.keys():\n",
    "                    current_bag[vocab2int[token.lemma_]] += 1\n",
    "                else:\n",
    "                    current_bag[-1] += 1\n",
    "\n",
    "        bow.append(current_bag)\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, labels = {}, {}\n",
    "\n",
    "for each in ['train', 'valid', 'test']:    \n",
    "    if each == 'train':\n",
    "        vocab2int, int2vocab = makeVocab(df_train[\"TITLE\"], 15)\n",
    "        df = df_train\n",
    "    elif each == 'valid':\n",
    "        df = df_valid\n",
    "    elif each == 'test':\n",
    "        df = df_test\n",
    "        \n",
    "    one_hot_publisher = pd.get_dummies(df['PUBLISHER'])\n",
    "    \n",
    "    bow_list = makeBOW(df[\"TITLE\"], vocab2int)\n",
    "    bow_df = pd.DataFrame(bow_list, columns=list(vocab2int.keys())+['UNK'])\n",
    "\n",
    "    datasets[each] = bow_df.join(one_hot_publisher)\n",
    "    datasets[each].to_csv(each + \".feature.txt\", index=False, sep=\"\\t\", encoding=\"utf-8\")\n",
    "    \n",
    "    intlabel = []\n",
    "    for label in df[\"CATEGORY\"]:\n",
    "        # (b = business, t = science and technology, e = entertainment, m = health)\n",
    "        intlabel.append(label2int[label])\n",
    "        \n",
    "    labels[each] = pd.Series(intlabel)\n",
    "\n",
    "features = datasets[\"train\"].columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52. 学習\n",
    "\n",
    "51で構築した学習データを用いて，ロジスティック回帰モデルを学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\", max_iter=5000, verbose=1, n_jobs=-1)\n",
    "clf.fit(datasets[\"train\"], labels[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53. 予測\n",
    "\n",
    "52で学習したロジスティック回帰モデルを用い，与えられた記事見出しからカテゴリとその予測確率を計算するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1 title seems to be \"e\" article (78.644%).\n",
      "No.2 title seems to be \"t\" article (86.641%).\n",
      "No.3 title seems to be \"b\" article (84.197%).\n",
      "No.4 title seems to be \"e\" article (33.191%).\n"
     ]
    }
   ],
   "source": [
    "text_title_e = \"New South Park season will come soon!\"\n",
    "text_title_t = \"Next iPhone might have USB-C\"\n",
    "text_title_b = \"Boeing 777 operation stops due to engine problem\"\n",
    "text_title_m = \"New vaccine for covid 19 have developed\"\n",
    "\n",
    "publishers = [\"Businessweek\", \"Contactmusic.com\", \"Daily Mail\", \"Huffington Post\", \"Reuters\"]\n",
    "onehot_publisher_bw = [1,0,0,0,0] # Businessweek\n",
    "onehot_publisher_cm = [0,1,0,0,0] # Contactmusic.com\n",
    "onehot_publisher_dm = [0,0,1,0,0] # Daily Mail\n",
    "onehot_publisher_hp = [0,0,0,1,0] # Huffington Post\n",
    "onehot_publisher_rt = [0,0,0,0,1] # Reuters\n",
    "\n",
    "given_inputs = [\n",
    "    [text_title_e] + onehot_publisher_dm, \n",
    "    [text_title_t] + onehot_publisher_bw,\n",
    "    [text_title_b] + onehot_publisher_rt,\n",
    "    [text_title_m] + onehot_publisher_hp\n",
    "]\n",
    "\n",
    "given_dfs = pd.DataFrame([])\n",
    "for label, given_input in zip([\"e\", \"t\", \"b\", \"m\"], given_inputs):\n",
    "    bow_list = makeBOW([given_input[0]], vocab2int)\n",
    "    converted_given = [bow_list[0] + given_input[1:]]\n",
    "    given_df = pd.DataFrame(\n",
    "        converted_given, \n",
    "        columns=list(vocab2int.keys())+['UNK']+publishers,\n",
    "        index=[label]\n",
    "    )\n",
    "\n",
    "    given_dfs = given_dfs.append(given_df)\n",
    "\n",
    "for (i, pred), prob in zip(enumerate(clf.predict(given_dfs)), clf.predict_proba(given_dfs)):\n",
    "    print(\"No.{:} title seems to be \\\"{:}\\\" article ({:.3f}%).\".format(i+1, int2label[pred], prob[pred]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54. 正解率の計測\n",
    "\n",
    "52で学習したロジスティック回帰モデルの正解率を，学習データおよび評価データ上で計測せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data is 0.930\n",
      "Accuracy on testing data is 0.894\n"
     ]
    }
   ],
   "source": [
    "train_correct_num, test_correct_num = 0, 0\n",
    "\n",
    "train_pred = clf.predict(datasets[\"train\"])\n",
    "for pred, true in zip(train_pred, labels[\"train\"]):\n",
    "    if pred == true:\n",
    "        train_correct_num += 1\n",
    "print(\"Accuracy on training data is {:.3f}\".format(train_correct_num/len(datasets[\"train\"])))\n",
    "\n",
    "test_pred = clf.predict(datasets[\"test\"])\n",
    "for pred, true in zip(test_pred, labels[\"test\"]):\n",
    "    if pred == true:\n",
    "        test_correct_num += 1\n",
    "print(\"Accuracy on testing data is {:.3f}\".format(test_correct_num/len(datasets[\"test\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55. 混同行列の作成\n",
    "\n",
    "52で学習したロジスティック回帰モデルの混同行列（confusion matrix）を，学習データおよび評価データ上で作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on training data:\n",
      "[[4339   79   89   16]\n",
      " [ 186  895  114   16]\n",
      " [  72   18 4105    5]\n",
      " [  60   16   76  586]]\n",
      "\n",
      "Confusion matrix on testing data:\n",
      "[[531  20  15   2]\n",
      " [ 36  92  15   6]\n",
      " [ 13   4 518   4]\n",
      " [ 12   3  12  51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_confusion_matrix = confusion_matrix(labels[\"train\"].to_list(), train_pred.tolist(), labels=list(int2label.keys()))\n",
    "test_confusion_matrix = confusion_matrix(labels[\"test\"].to_list(), test_pred.tolist(), labels=list(int2label.keys()))\n",
    "\n",
    "print(\"Confusion matrix on training data:\")\n",
    "print(train_confusion_matrix)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Confusion matrix on testing data:\")\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56. 適合率，再現率，F1スコアの計測\n",
    "\n",
    "52で学習したロジスティック回帰モデルの適合率，再現率，F1スコアを，評価データ上で計測せよ．カテゴリごとに適合率，再現率，F1スコアを求め，カテゴリごとの性能をマイクロ平均（micro-average）とマクロ平均（macro-average）で統合せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: business\n",
      "\tPrecision: 0.897\n",
      "\tRecall: 0.935\n",
      "\tF1-Score: 0.916\n",
      "================================================\n",
      "Category: science and technology\n",
      "\tPrecision: 0.773\n",
      "\tRecall: 0.617\n",
      "\tF1-Score: 0.687\n",
      "================================================\n",
      "Category: entertainment\n",
      "\tPrecision: 0.925\n",
      "\tRecall: 0.961\n",
      "\tF1-Score: 0.943\n",
      "================================================\n",
      "Category: health\n",
      "\tPrecision: 0.810\n",
      "\tRecall: 0.654\n",
      "\tF1-Score: 0.723\n",
      "================================================\n",
      "Average_micro: 0.894\n",
      "================================================\n",
      "Precision_macro: 0.851\n",
      "Recall_macro: 0.792\n",
      "F1-Score_macro: 0.817\n"
     ]
    }
   ],
   "source": [
    "label2category = {\n",
    "    \"b\": \"business\",\n",
    "    \"t\": \"science and technology\",\n",
    "    \"e\": \"entertainment\",\n",
    "    \"m\": \"health\"\n",
    "}\n",
    "\n",
    "precisions, recalls, f1s = [], [], []\n",
    "\n",
    "for i, label in int2label.items():\n",
    "    precision = test_confusion_matrix[i,i] / np.sum(test_confusion_matrix[:,i])\n",
    "    recall = test_confusion_matrix[i,i] / np.sum(test_confusion_matrix[i,:])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "    print(\"Category: {:}\".format(label2category[label]))\n",
    "    print(\"\\tPrecision: {:.3f}\".format(precision))\n",
    "    print(\"\\tRecall: {:.3f}\".format(recall))\n",
    "    print(\"\\tF1-Score: {:.3f}\".format(f1))\n",
    "    print(\"=\"*48)\n",
    "\n",
    "tp = np.sum([test_confusion_matrix[i,i] for i in range(len(test_confusion_matrix))])\n",
    "not_tp = np.sum([test_confusion_matrix[i,j] for i in range(len(test_confusion_matrix)) \n",
    "                                            for j in range(len(test_confusion_matrix)) \n",
    "                                            if i != j])\n",
    "print(\"Average_micro: {:.3f}\".format(tp/(tp+not_tp)))\n",
    "\n",
    "print(\"=\"*48)\n",
    "\n",
    "precision_macro = np.average(precisions)\n",
    "recall_macro = np.average(recalls)\n",
    "f1_macro = np.average(f1s)\n",
    "\n",
    "print(\"Precision_macro: {:.3f}\".format(precision_macro))\n",
    "print(\"Recall_macro: {:.3f}\".format(recall_macro))\n",
    "print(\"F1-Score_macro: {:.3f}\".format(f1_macro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57. 特徴量の重みの確認\n",
    "\n",
    "52で学習したロジスティック回帰モデルの中で，重みの高い特徴量トップ10と，重みの低い特徴量トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: business\n",
      "\tTop-10 important features:\n",
      "\t\tbank (2.138)\n",
      "\t\tfed (1.851)\n",
      "\t\tairline (1.698)\n",
      "\t\tobamacare (1.682)\n",
      "\t\tbuy (1.631)\n",
      "\t\tmcdonald (1.627)\n",
      "\t\tloan (1.604)\n",
      "\t\tbell (1.594)\n",
      "\t\tfitch (1.577)\n",
      "\t\tukraine (1.535)\n",
      "\tTop-10 un-important features:\n",
      "\t\tContactmusic.com (-1.817)\n",
      "\t\tvictim (-1.617)\n",
      "\t\taereo (-1.614)\n",
      "\t\tebola (-1.415)\n",
      "\t\tfestival (-1.356)\n",
      "\t\treview (-1.312)\n",
      "\t\ttv (-1.221)\n",
      "\t\tcell (-1.168)\n",
      "\t\tapproval (-1.156)\n",
      "\t\tkill (-1.149)\n",
      "Category: science and technology\n",
      "\tTop-10 important features:\n",
      "\t\tclimate (2.786)\n",
      "\t\tfacebook (2.770)\n",
      "\t\tmicrosoft (2.752)\n",
      "\t\tgoogle (2.695)\n",
      "\t\tnasa (2.610)\n",
      "\t\tapple (2.309)\n",
      "\t\theartbleed (2.151)\n",
      "\t\tfcc (2.014)\n",
      "\t\ttesla (1.991)\n",
      "\t\tmoon (1.966)\n",
      "\tTop-10 un-important features:\n",
      "\t\tman (-1.264)\n",
      "\t\tpercent (-1.246)\n",
      "\t\tdrug (-1.206)\n",
      "\t\tsurge (-1.062)\n",
      "\t\tcancer (-1.032)\n",
      "\t\toffice (-0.988)\n",
      "\t\tyoung (-0.982)\n",
      "\t\texpectation (-0.981)\n",
      "\t\tjump (-0.978)\n",
      "\t\trecord (-0.968)\n",
      "Category: entertainment\n",
      "\tTop-10 important features:\n",
      "\t\tContactmusic.com (2.414)\n",
      "\t\tfilm (2.056)\n",
      "\t\tchris (1.873)\n",
      "\t\ttrailer (1.836)\n",
      "\t\tmovie (1.780)\n",
      "\t\tkardashian (1.666)\n",
      "\t\tfestival (1.623)\n",
      "\t\tactor (1.592)\n",
      "\t\tmusic (1.568)\n",
      "\t\teaster (1.563)\n",
      "\tTop-10 un-important features:\n",
      "\t\tscientist (-1.906)\n",
      "\t\tgoogle (-1.562)\n",
      "\t\tnasa (-1.400)\n",
      "\t\tBusinessweek (-1.397)\n",
      "\t\trecall (-1.380)\n",
      "\t\tbuy (-1.361)\n",
      "\t\trisk (-1.303)\n",
      "\t\tchina (-1.296)\n",
      "\t\tprotect (-1.270)\n",
      "\t\tbrain (-1.266)\n",
      "Category: health\n",
      "\tTop-10 important features:\n",
      "\t\tebola (3.204)\n",
      "\t\tfda (2.427)\n",
      "\t\tcdc (2.195)\n",
      "\t\tstudy (2.085)\n",
      "\t\tcancer (2.079)\n",
      "\t\tmer (2.054)\n",
      "\t\tbrain (2.029)\n",
      "\t\tdrug (1.838)\n",
      "\t\tapproval (1.831)\n",
      "\t\tcigarette (1.817)\n",
      "\tTop-10 un-important features:\n",
      "\t\tdeal (-1.179)\n",
      "\t\tclimate (-1.095)\n",
      "\t\tterm (-1.072)\n",
      "\t\tbook (-1.005)\n",
      "\t\tbegin (-0.958)\n",
      "\t\tsue (-0.933)\n",
      "\t\tmiss (-0.931)\n",
      "\t\tgame (-0.927)\n",
      "\t\tplay (-0.920)\n",
      "\t\tgm (-0.908)\n"
     ]
    }
   ],
   "source": [
    "for labelint, coef in zip(clf.classes_, clf.coef_):\n",
    "    category = label2category[int2label[labelint]]\n",
    "    top10, bottom10 = np.argsort(-coef)[:10], np.argsort(coef)[:10]\n",
    "    \n",
    "    print(\"Category: {:}\".format(category))\n",
    "\n",
    "    print(\"\\tTop-10 important features:\")\n",
    "    for index in top10:\n",
    "        print(\"\\t\\t{:} ({:.3f})\".format(features[index], coef[index]))\n",
    "        \n",
    "    print(\"\\tTop-10 un-important features:\")\n",
    "    for index in bottom10:\n",
    "        print(\"\\t\\t{:} ({:.3f})\".format(features[index], coef[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 58. 正則化パラメータの変更\n",
    "\n",
    "ロジスティック回帰モデルを学習するとき，正則化パラメータを調整することで，学習時の過学習（overfitting）の度合いを制御できる．異なる正則化パラメータでロジスティック回帰モデルを学習し，学習データ，検証データ，および評価データ上の正解率を求めよ．実験の結果は，正則化パラメータを横軸，正解率を縦軸としたグラフにまとめよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sns.set()\n",
    "\n",
    "Cs = list(map(round, [i*.2 for i in range(1, 11)], [1]*10))\n",
    "accs_train, accs_valid, accs_test = [], [], []\n",
    "\n",
    "for c in Cs:\n",
    "    clf = LogisticRegression(solver=\"lbfgs\", C=c, max_iter=5000, verbose=0, n_jobs=-1)\n",
    "    clf.fit(datasets[\"train\"], labels[\"train\"])\n",
    "\n",
    "    accs_train.append(accuracy_score(labels[\"train\"], clf.predict(datasets[\"train\"])))\n",
    "    accs_valid.append(accuracy_score(labels[\"valid\"], clf.predict(datasets[\"valid\"])))\n",
    "    accs_test.append(accuracy_score(labels[\"test\"], clf.predict(datasets[\"test\"])))\n",
    "\n",
    "accs_train_df = pd.DataFrame({\n",
    "    \"C\": Cs,\n",
    "    \"Accuracy\": accs_train,\n",
    "    \"Legend\": \"Train\"})\n",
    "\n",
    "accs_valid_df = pd.DataFrame({\n",
    "    \"C\": Cs,\n",
    "    \"Accuracy\": accs_valid,\n",
    "    \"Legend\": \"Valid\"})\n",
    "\n",
    "accs_test_df = pd.DataFrame({\n",
    "    \"C\": Cs,\n",
    "    \"Accuracy\": accs_test,\n",
    "    \"Legend\": \"Test\"})\n",
    "\n",
    "data = pd.concat([accs_train_df, accs_valid_df, accs_test_df])\n",
    "\n",
    "ax = sns.pointplot(x=\"C\", y=\"Accuracy\", data=data, hue=\"Legend\")\n",
    "ax.set(xlabel=\"C\", ylabel=\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 59. ハイパーパラメータの探索\n",
    "\n",
    "学習アルゴリズムや学習パラメータを変えながら，カテゴリ分類モデルを学習せよ．検証データ上の正解率が最も高くなる学習アルゴリズム・パラメータを求めよ．また，その学習アルゴリズム・パラメータを用いたときの評価データ上の正解率を求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [04:45<00:00, 40.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression(max_iter=1000)', 0.8740629685157422),\n",
       " ('MLPClassifier(max_iter=1000)', 0.8478260869565218),\n",
       " ('SVC()', 0.8403298350824587),\n",
       " ('RandomForestClassifier(n_estimators=1000)', 0.8388305847076462),\n",
       " ('DecisionTreeClassifier()', 0.8013493253373315),\n",
       " ('KNeighborsClassifier()', 0.7406296851574213),\n",
       " ('GaussianNB()', 0.6454272863568216)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "svm = SVC()\n",
    "kn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "\n",
    "classifiers = [lr, svm, kn, nb, dt, rf, mlp]\n",
    "f1s = {}\n",
    "\n",
    "for classifier in tqdm(classifiers):\n",
    "    classifier.fit(datasets['train'], labels['train'])\n",
    "    prediction = classifier.predict(datasets['valid'])\n",
    "    \n",
    "    f1s[str(classifier)] = f1_score(labels['valid'], prediction, average='micro')\n",
    "\n",
    "sorted(f1s.items(), key=lambda x:-x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-30 14:43:44,265]\u001b[0m A new study created in memory with name: no-name-1b856d8f-be33-4d48-bc3a-e66ed10851b9\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:43:49,487]\u001b[0m Trial 0 finished with value: 0.8718140929535231 and parameters: {'C': 1.2166093968392346, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:44:08,698]\u001b[0m Trial 1 finished with value: 0.8545727136431784 and parameters: {'C': 3.969560441672061, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:44:27,699]\u001b[0m Trial 2 finished with value: 0.8545727136431784 and parameters: {'C': 9.217049499352116, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:44:46,562]\u001b[0m Trial 3 finished with value: 0.8523238380809596 and parameters: {'C': 0.8544099283963681, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:44:49,700]\u001b[0m Trial 4 finished with value: 0.8703148425787106 and parameters: {'C': 2.573816211836239, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:45:08,954]\u001b[0m Trial 5 finished with value: 0.8545727136431784 and parameters: {'C': 5.566240347868091, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:45:16,252]\u001b[0m Trial 6 finished with value: 0.8620689655172413 and parameters: {'C': 8.78849447984516, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:45:35,094]\u001b[0m Trial 7 finished with value: 0.8530734632683659 and parameters: {'C': 1.4521343723013285, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:45:53,923]\u001b[0m Trial 8 finished with value: 0.8530734632683659 and parameters: {'C': 1.1481305949966794, 'solver': 'sag'}. Best is trial 0 with value: 0.8718140929535231.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:45:56,883]\u001b[0m Trial 9 finished with value: 0.8725637181409295 and parameters: {'C': 6.342468035646883, 'solver': 'lbfgs'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:45:59,355]\u001b[0m Trial 10 finished with value: 0.8710644677661169 and parameters: {'C': 6.515614348340902, 'solver': 'lbfgs'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:06,384]\u001b[0m Trial 11 finished with value: 0.8665667166416792 and parameters: {'C': 7.1181336964529605, 'solver': 'newton-cg'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:11,655]\u001b[0m Trial 12 finished with value: 0.8718140929535231 and parameters: {'C': 4.020311791303845, 'solver': 'newton-cg'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:13,741]\u001b[0m Trial 13 finished with value: 0.8703148425787106 and parameters: {'C': 7.7958491811231525, 'solver': 'lbfgs'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:15,759]\u001b[0m Trial 14 finished with value: 0.8718140929535231 and parameters: {'C': 4.997859160392339, 'solver': 'lbfgs'}. Best is trial 9 with value: 0.8725637181409295.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:20,913]\u001b[0m Trial 15 finished with value: 0.8733133433283359 and parameters: {'C': 2.7910717860070466, 'solver': 'newton-cg'}. Best is trial 15 with value: 0.8733133433283359.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:26,465]\u001b[0m Trial 16 finished with value: 0.8733133433283359 and parameters: {'C': 2.8102806300273335, 'solver': 'newton-cg'}. Best is trial 15 with value: 0.8733133433283359.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:31,470]\u001b[0m Trial 17 finished with value: 0.8725637181409295 and parameters: {'C': 2.8791863625795475, 'solver': 'newton-cg'}. Best is trial 15 with value: 0.8733133433283359.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:36,449]\u001b[0m Trial 18 finished with value: 0.8740629685157422 and parameters: {'C': 2.6463018398124354, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8740629685157422.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:41,760]\u001b[0m Trial 19 finished with value: 0.8718140929535231 and parameters: {'C': 4.252451177194857, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8740629685157422.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:46,621]\u001b[0m Trial 20 finished with value: 0.8740629685157422 and parameters: {'C': 2.1413503923090857, 'solver': 'newton-cg'}. Best is trial 18 with value: 0.8740629685157422.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:52,065]\u001b[0m Trial 21 finished with value: 0.8755622188905547 and parameters: {'C': 2.33301810331873, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:46:56,765]\u001b[0m Trial 22 finished with value: 0.8733133433283359 and parameters: {'C': 1.9871230177612236, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:00,070]\u001b[0m Trial 23 finished with value: 0.8620689655172413 and parameters: {'C': 0.1942122474095438, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:03,471]\u001b[0m Trial 24 finished with value: 0.8703148425787106 and parameters: {'C': 0.350426030535683, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:08,919]\u001b[0m Trial 25 finished with value: 0.8725637181409295 and parameters: {'C': 3.554288023583319, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:13,913]\u001b[0m Trial 26 finished with value: 0.8733133433283359 and parameters: {'C': 1.9722286282758268, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:18,627]\u001b[0m Trial 27 finished with value: 0.8733133433283359 and parameters: {'C': 1.9800172841962245, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:24,338]\u001b[0m Trial 28 finished with value: 0.8695652173913043 and parameters: {'C': 4.986503635149001, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:29,930]\u001b[0m Trial 29 finished with value: 0.8725637181409295 and parameters: {'C': 3.3454726718882997, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:33,720]\u001b[0m Trial 30 finished with value: 0.8748125937031486 and parameters: {'C': 0.6142158885636633, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:37,613]\u001b[0m Trial 31 finished with value: 0.8748125937031486 and parameters: {'C': 0.6783394065717967, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:41,650]\u001b[0m Trial 32 finished with value: 0.8740629685157422 and parameters: {'C': 0.654636890226058, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:45,537]\u001b[0m Trial 33 finished with value: 0.8740629685157422 and parameters: {'C': 0.6444328343968491, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:50,257]\u001b[0m Trial 34 finished with value: 0.8718140929535231 and parameters: {'C': 1.3362225888234052, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:53,185]\u001b[0m Trial 35 finished with value: 0.8500749625187405 and parameters: {'C': 0.11488173723381379, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:47:57,217]\u001b[0m Trial 36 finished with value: 0.8748125937031486 and parameters: {'C': 0.768995005006073, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:48:01,767]\u001b[0m Trial 37 finished with value: 0.8718140929535231 and parameters: {'C': 1.4124533004073085, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:48:20,636]\u001b[0m Trial 38 finished with value: 0.8523238380809596 and parameters: {'C': 0.901366241828006, 'solver': 'sag'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:48:23,846]\u001b[0m Trial 39 finished with value: 0.8613193403298351 and parameters: {'C': 0.20437568778661042, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:48:42,569]\u001b[0m Trial 40 finished with value: 0.8523238380809596 and parameters: {'C': 1.636785944000691, 'solver': 'sag'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:48:48,434]\u001b[0m Trial 41 finished with value: 0.8755622188905547 and parameters: {'C': 2.2130294696182222, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:48:52,303]\u001b[0m Trial 42 finished with value: 0.8748125937031486 and parameters: {'C': 0.7217580803007707, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:48:56,538]\u001b[0m Trial 43 finished with value: 0.8733133433283359 and parameters: {'C': 1.0855214843562253, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:01,801]\u001b[0m Trial 44 finished with value: 0.8755622188905547 and parameters: {'C': 2.416811454660862, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:07,248]\u001b[0m Trial 45 finished with value: 0.8725637181409295 and parameters: {'C': 3.2502455086014796, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:09,349]\u001b[0m Trial 46 finished with value: 0.8703148425787106 and parameters: {'C': 4.46297551025059, 'solver': 'lbfgs'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:14,595]\u001b[0m Trial 47 finished with value: 0.8755622188905547 and parameters: {'C': 2.271246496656795, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:19,636]\u001b[0m Trial 48 finished with value: 0.8755622188905547 and parameters: {'C': 2.2656431533758066, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:49:38,687]\u001b[0m Trial 49 finished with value: 0.8530734632683659 and parameters: {'C': 2.278045689823632, 'solver': 'sag'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:44,308]\u001b[0m Trial 50 finished with value: 0.8718140929535231 and parameters: {'C': 3.738544466925947, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:49,742]\u001b[0m Trial 51 finished with value: 0.8725637181409295 and parameters: {'C': 3.078839456902977, 'solver': 'newton-cg'}. Best is trial 21 with value: 0.8755622188905547.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:49:55,102]\u001b[0m Trial 52 finished with value: 0.876311844077961 and parameters: {'C': 2.462466886896988, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:00,494]\u001b[0m Trial 53 finished with value: 0.8755622188905547 and parameters: {'C': 2.4000273795435416, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:05,707]\u001b[0m Trial 54 finished with value: 0.8755622188905547 and parameters: {'C': 2.4840123485998413, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:07,748]\u001b[0m Trial 55 finished with value: 0.876311844077961 and parameters: {'C': 1.6778219304725095, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:09,867]\u001b[0m Trial 56 finished with value: 0.8710644677661169 and parameters: {'C': 2.8389203253892292, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:11,908]\u001b[0m Trial 57 finished with value: 0.8718140929535231 and parameters: {'C': 1.7904002455213754, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:14,015]\u001b[0m Trial 58 finished with value: 0.8703148425787106 and parameters: {'C': 9.777386830705066, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:16,166]\u001b[0m Trial 59 finished with value: 0.8710644677661169 and parameters: {'C': 2.612259830266123, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:18,231]\u001b[0m Trial 60 finished with value: 0.8710644677661169 and parameters: {'C': 4.538051716693309, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:23,285]\u001b[0m Trial 61 finished with value: 0.8718140929535231 and parameters: {'C': 1.771686872593399, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:28,162]\u001b[0m Trial 62 finished with value: 0.8755622188905547 and parameters: {'C': 2.4951019893251782, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:33,744]\u001b[0m Trial 63 finished with value: 0.8718140929535231 and parameters: {'C': 3.116340784150906, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:35,822]\u001b[0m Trial 64 finished with value: 0.8740629685157422 and parameters: {'C': 3.7325495141578293, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:40,646]\u001b[0m Trial 65 finished with value: 0.8755622188905547 and parameters: {'C': 2.5091554081387915, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:45,461]\u001b[0m Trial 66 finished with value: 0.8710644677661169 and parameters: {'C': 1.5650493327331838, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:49,712]\u001b[0m Trial 67 finished with value: 0.8703148425787106 and parameters: {'C': 1.2306083052261974, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:50:55,297]\u001b[0m Trial 68 finished with value: 0.8718140929535231 and parameters: {'C': 3.480027607242843, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:00,727]\u001b[0m Trial 69 finished with value: 0.8718140929535231 and parameters: {'C': 4.019901509312433, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:02,808]\u001b[0m Trial 70 finished with value: 0.8703148425787106 and parameters: {'C': 2.9507958674105943, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:07,609]\u001b[0m Trial 71 finished with value: 0.876311844077961 and parameters: {'C': 2.460409166067574, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:12,671]\u001b[0m Trial 72 finished with value: 0.8755622188905547 and parameters: {'C': 2.3129512008969573, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:18,122]\u001b[0m Trial 73 finished with value: 0.8740629685157422 and parameters: {'C': 2.661914353151045, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:23,109]\u001b[0m Trial 74 finished with value: 0.8740629685157422 and parameters: {'C': 2.0868518482866647, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:28,274]\u001b[0m Trial 75 finished with value: 0.8725637181409295 and parameters: {'C': 1.8296157108313402, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:33,018]\u001b[0m Trial 76 finished with value: 0.8718140929535231 and parameters: {'C': 1.4863735479443818, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:51:51,953]\u001b[0m Trial 77 finished with value: 0.8530734632683659 and parameters: {'C': 2.5018949847447245, 'solver': 'sag'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:51:56,443]\u001b[0m Trial 78 finished with value: 0.8725637181409295 and parameters: {'C': 2.034529872785534, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:02,347]\u001b[0m Trial 79 finished with value: 0.868815592203898 and parameters: {'C': 5.641226376902332, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:06,627]\u001b[0m Trial 80 finished with value: 0.8710644677661169 and parameters: {'C': 1.1567447367944823, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:11,470]\u001b[0m Trial 81 finished with value: 0.8748125937031486 and parameters: {'C': 2.524119528099642, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:16,796]\u001b[0m Trial 82 finished with value: 0.8740629685157422 and parameters: {'C': 2.130175546486174, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:21,814]\u001b[0m Trial 83 finished with value: 0.8725637181409295 and parameters: {'C': 2.8809878398558864, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:27,416]\u001b[0m Trial 84 finished with value: 0.8725637181409295 and parameters: {'C': 3.272882942742239, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:32,503]\u001b[0m Trial 85 finished with value: 0.8755622188905547 and parameters: {'C': 2.272951718999106, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:37,363]\u001b[0m Trial 86 finished with value: 0.8718140929535231 and parameters: {'C': 1.6902313551995756, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:42,419]\u001b[0m Trial 87 finished with value: 0.8733133433283359 and parameters: {'C': 1.9570069668758479, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:46,642]\u001b[0m Trial 88 finished with value: 0.8748125937031486 and parameters: {'C': 0.9765964409593813, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:51,506]\u001b[0m Trial 89 finished with value: 0.8755622188905547 and parameters: {'C': 2.319687585599061, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:52:56,507]\u001b[0m Trial 90 finished with value: 0.8733133433283359 and parameters: {'C': 2.790891606836482, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:01,620]\u001b[0m Trial 91 finished with value: 0.8718140929535231 and parameters: {'C': 3.1037250292378236, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:06,439]\u001b[0m Trial 92 finished with value: 0.8748125937031486 and parameters: {'C': 2.5206921626013856, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:11,404]\u001b[0m Trial 93 finished with value: 0.8755622188905547 and parameters: {'C': 2.4133587527184557, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:15,760]\u001b[0m Trial 94 finished with value: 0.8718140929535231 and parameters: {'C': 1.4174422570867875, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:20,521]\u001b[0m Trial 95 finished with value: 0.8733133433283359 and parameters: {'C': 1.8650720633234645, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:22,644]\u001b[0m Trial 96 finished with value: 0.8710644677661169 and parameters: {'C': 2.179225111516619, 'solver': 'lbfgs'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "/usr/local/anaconda3/envs/nlp/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "\u001b[32m[I 2021-03-30 14:53:41,625]\u001b[0m Trial 97 finished with value: 0.8538230884557722 and parameters: {'C': 3.4731651016175857, 'solver': 'sag'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:47,706]\u001b[0m Trial 98 finished with value: 0.863568215892054 and parameters: {'C': 7.89853800877119, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n",
      "\u001b[32m[I 2021-03-30 14:53:52,570]\u001b[0m Trial 99 finished with value: 0.8755622188905547 and parameters: {'C': 2.2601232709258636, 'solver': 'newton-cg'}. Best is trial 52 with value: 0.876311844077961.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=52, values=[0.876311844077961], datetime_start=datetime.datetime(2021, 3, 30, 14, 49, 49, 743577), datetime_complete=datetime.datetime(2021, 3, 30, 14, 49, 55, 101938), params={'C': 2.462466886896988, 'solver': 'newton-cg'}, distributions={'C': UniformDistribution(high=10.0, low=0.1), 'solver': CategoricalDistribution(choices=('newton-cg', 'lbfgs', 'sag'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=52, state=TrialState.COMPLETE, value=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'C': trial.suggest_float(\"C\", 0.1, 10),\n",
    "        'solver': trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'sag'])\n",
    "    }\n",
    "    classifier_obj = LogisticRegression(**params, penalty='l2', n_jobs=-1)\n",
    "    \n",
    "    classifier_obj.fit(datasets['train'], labels['train'])\n",
    "    prediction = classifier_obj.predict(datasets['valid'])\n",
    "    score = f1_score(labels['valid'], prediction, average='micro')\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8935532233883059"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best = LogisticRegression(**study.best_params, max_iter=1000, n_jobs=-1)\n",
    "lr_best.fit(\n",
    "    pd.concat([datasets['train'], datasets['valid']]),\n",
    "    pd.concat([labels['train'], labels['valid']])\n",
    ")\n",
    "prediction = lr_best.predict(datasets['test'])\n",
    "\n",
    "score = f1_score(labels['test'], prediction, average='micro')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
